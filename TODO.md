### Top remaining features before v1.0.0

Also github integration:

- A dope feature to bake into github extensions is the ability for it to act also as a communicator with the github
  PR. When you start a pipeline not only does it handle the webhooks of starting the pipeline, but it will also
  mark the PR in question as pending and query the Gofer API to figure out when it's done and mark the pipeline
  as completed. Could also include some other goodies just like any other CI/CD platform.

### Canaried pipelines

- With versioned pipelines we now need the ability for Gofer to roll out your pipeline for you and watch telemetry on it.
- We need to add "update methods" to pipeline settings which will control the manner in which we roll out updates. Runs will need to include which version of the pipeline has run

### API

- The API needs proper validation for all endpoints and probably some fuzz testing.
- User should also be able to give their builds a per-task timeout. Limit this to 5 min - 8 hours. If this is not set the scheduler should set it to 8 hours.
- We should have a feature that allows individual tasks and pipelines the ability to turn off logging.
- Implement a Global timeout for all runs.
- Implement the feature allowing people to attach into their containers and allow maintainers to turn that off.
- Offer the ability to run two different versions of a container at the same time so that people can slowly roll out new jobs in a safe fashion. (green blue/canary)
- Purely for recovering lost containers, we can usually query the engine to ask it what time this container stopped and started. This way we can have more accurate running times instead of just leaving it as whenever
  the server restarted.
- The CLI does some checking to make sure that the config pushed will work. Should the API do further checking when someone registers a new pipeline config? Or should we just error?
- When you ask to list a pipeline or run or task run, if that thing or it's parent does not exist we should tell the user it doesn't.(This is most likely just simply passing up the not found error from the db)
- The storage layer could benefit from more autogenerated code: https://docs.sqlc.dev/en/latest/tutorials/getting-started-postgresql.html
- Reconstructing a timeline of any given pipeline run would be a really cool feature.

### SDK

- Rust SDK tasks methods needs a better UX. Maybe a macro that will wrap the user's items in a box for them?
- Rust sdk needs documentation.
- Rust documentation possibly needs to be on cargo.io.
- Rust needs more love in general, the stack rank has golang first.

### CLI

- Provide custom errors downstream via grpc metadata so the CLI can pass back intelligent errors to users.
- Improve CLI errors overall.
- Add command line options for controlling pagination
- Combined logs feature: Ability to attach to all task runs at the same time and dump from the run.
- We should have a watch function for run that nicely displays the task runs as they start and finish.
  (We could even have the active task_runs display the last 5 log lines as it runs each in their own personal terminal print load bar thing)
- CLI now just compiles from language. This means that we can also just straight up read from things like json/toml since it all compiles back to proto anyway.
- https://github.com/clintjedwards/gofer/commit/955e1b7da76fdfa5aa26bcb5dd0b138af605aa45
  - Reimplement this and make it so it shows the parent status.
- Create an init function for both rust and golang(simply just prompts you for your language) and then creates a new default vanilla pipeline. (similar to the old "config init" command)
- Inspiration for CLI design: https://github.com/bensadeh/circumflex
  - Look into bubble tea for some interactions.
- A diff command might be awesome.
- Expand the CLI up command to actually walk the user through the deployment using watch. Right now it just starts the deployment and walks away.
- When a user runs up, should we compare their config to known configs and reject
  registration if it's the same?

### Scheduler

- Implement CPU/MEMORY per task values since all non-local schedulers will need this.
- It would be cool to have at least one other scheduler. Nomad is a great scheduler for this.

### SecretStore

- It would be cool to get at least one other secret store implementation like Vault.
  - For an extension like vault we manage the read and write in the same way we would for bolt. So vault gives us a prefix
    path and we essentially just used that prefix path to store secrets.

### Extensions

- Test that unsubscribing works with all extensions. And create a test suite that extensions can run against.
- The interval extension should create jitter of about 2-5 mins. During that time it can choose when to start counting to extension an event. This is so that when we restart the server all events don't perfectly line up with each other and cause a storm. There might be other, smarter ways to handle this queue and api calling as well.
- Extensions should follow semver. Extensions that use the same major version of Gofer should be compatible.
- If a extension by the same name is already installed, we should refuse to install another but instead allow the user to update it.
- Extensions should be able to report details about their execution somehow. It would be nice when looking at my pipeline run to see exactly when the extension performed certain actions. And be able to troubleshoot an extension that is taking overly long.

#### More extensions:

There are several useful things we can do with the concept of extensions:

- There should be a way to monitor another pipeline(in any namespace) and then
  run your pipeline based on that pipeline.
- There should be a way to monitor any pipeline and then notify yourself(email, slack, whatever) on a certain cadence. Things like:
  - If pipeline fails 3 runs in a row.
  - If pipeline failure rate ever dives below certain percentage.
  - If total time of a run exceeds a given duration.
  - When a run finishes.
  - When a run fails.
  - If a particular task run fails or succeeds.

We can also create bespoke common tasks that do this.

### Things I need to do but probably will never get around to

- Test registry auth.
- Write tests for all "TO" and "FROM" functions.
- For certain routes we need to pass around the logger so that we can automatically
  inject namespace and pipeline.
- We need to refactor logging for some routes to build on top of each other so that they we automatically get things
  like namespace, pipeline.
- Terraform provider for installing extensions.

### General

- For FromProto methods where the reference might be nil; auto-create the reference before attempting to fill it. Look at registry auth for an example.
- Metrics via openTelemetry
- Check that when we create the run specific token for a run and enter it into the user's run stuff. We also need to make sure we clean that token up after the run is done.
- Create a container for custom use that has gofer-cli already packed in and possibly allows
  - Think about making a new task type that you can pass commands to that automatically uses the gofer container. So users can get zero to code ultra-fast.

### Rough spots in design

- It currently runs as a singleton, not distributed. There are a lot of things to figure out here for a full distributed system.
- The umbrella for this tool is large. There is a reason Jenkins still leads, the plugin ecosystem needs significant time to catch up to its large ecosystem and then to do it properly would require non-insignificant maintenance.
- Write some documentation on the Domain model design. Sometimes it can be hard to wrap your head around going from Config -> SDK -> Proto -> Models and they are all named fairly similarly.

### Public Gofer ideas

- Can we give user's a timeout that is super low, like a total container runtime of a few minutes. The only way to get past this is to sign up from a differnet IP. That way you can try it out, but you can't just run your own crypto shit on it.
- Once the timeout is up we simply log the IP and prevent that user from making any more requests.
- We might be able to get this for free in some golang ratelimiting libraries, we'd have to have the user sign up in some way first in order to prevent people from abusing. We can ratelimit routes that need to be always public per IP.
- How do we secure the running of containers? We can do somethings like preventing root user for the container: https://firecracker-microvm.github.io/

### Documentation

- Server configuration reference should have one more field on whether it is required or not.
- Extension documentation:
  - Extensions now have two required functions, extension installations and extension runs
    - Run is the service, Install runs a small program meant to help with installation.
  - How to test extensions
  - How to work with extensions locally
  - Explanation of the SDK on writing extensions
- Add a section where we create a new extension using a extension that has already been created. as the example for new extensions in the docs
- Secrets explanation. Why is there global secrets and pipelines secrets? Whats the difference.
  - We needed a way to store secrets for common tasks which might be used for any pipeline
    and a way to store secrets for user's individual pipelines.
  - Global secrets can only be set by administrators
- Write a small RFC for Gofer. Why were the decisions made the way they were, what was the purpose of the project, etc etc.
  - We are forgoing having cli spit out Json due to gofer having an API, the cli is meant for humans and shouldn't be used by programs.
- Write copius notes on commontasks and extensions layout. The difference between user passed config and system passed config. And suggest a way to collect those.
  - Gofer passes them one set of env vars from the gofer system itself
    These are prefixed with `gofer_plugin_system_{var}`
  - Gofer then passes them another set of env vars from the admin that was set up through registration.
    These are prefixed with `gofer_plugin_config_{var}`
  - Gofer then passes them another set of env vars from the user's own config.
    These are prefixed with `gofer_plugin_param_{var}`
- Write better documentation on how to spin Gofer up locally so you can test out your pipeline.

### On the floor

- Global secret namespaces are implemented on the storage level. Now it needs to be enforced at the run level.
  When we populate secrets we need to make sure the pipeline is in the allowed namespaces.

  - We also need to support regex for namespaces and tell the CLI that you can do this. Users should be able
    to allow all namespaces with a particular prefix to inherit global secrets.
  - We also need to check that secrets are automatically redacted from task-run logs.

- We can possibly get rid of common tasks now that the extensions work how they do. To do this I think we would also
  need to bolster the global secrets feature to support giving keys to only pipelines within a certain namespace.
- Now that extensions can do anything, maybe it's time to change the way we interact with them.
  Instead of Gofer watching for each extension's ping, maybe they just hit the API if they have something
  to say. This makes it so extensions aren't so snowflaky and are just apis that Gofer can talk to.
  It also opens up the possibility for external extensions that Gofer just communicates with remotely without
  spinning up any docker container.
- Think more about event naming, right now the naming is kinda weird because we're trying events to the objects that we normally
  work with like pipelines and runs. Maybe that grouping should be in documentation only? Including it in the name can make for
  awkward confusing names.
  - For instance: EventStartedDeployPipeline instead of EventStartedPipelineDeploy
- Because things are handled at the current abstraction layer for users who just want to throw code and have it work it can be difficult. Users who operate within Gofer will have to do at least some thought about repositories downloads, possibly caching, transferring between containers, etc. These are all things that some CI/CD systems give for free. The managing of large git repos is the biggest pain point here.
- To give people the ability to cache certain important items like repositories we can create a special ubuntu container with a fuse file system. We can then allow people to use this container to connect back to the object fs and make common tasks like storing your repo easy.
  - The hard part about this is for git repos. If we have one user who has checked out a branch we now have to implement a copy on write situation.
  - An alternative to this is we can use things like the Github trigger to help users manage their PRs. The github trigger can manage it just using Gofer's object store, simply storying a few select things for each repo. Before the user accesses it in their container the trigger can inject the proper path for the repo they want. This would require a fairly expensive operation of the
    github trigger downloading the repo, updating it, switching the branch, and then pushing that back up....only to be downloaded by the user in the near future.
  - instead of downloading and updating, just make the Github trigger cache the repo locally, when a user needs it we just make sure it's up to date, and upload it to the path, the user can then just download from that path
  - We can possibly do smarter things here also, like only write the files from the extension that have changed from a base version of the git repository, Do copy on write to the container. All hard problems that sounds interesting.
- https://fly.io/docs/litefs/getting-started/ You can actually just pull files straight from docker kekw
- In the CLI as the user a question with a prompt like ?
- Update the CLI to make extension sub say `gofer pipeline extend <params here>`
- We need to address all the minor bugs around namespaces and pipelines and their existance when calling upon the api
- Global secret force replace does not work, probably should just change to and update.
